import io
import grpc
import pydub
import argparse
from aiogram import Bot, types
from aiogram.dispatcher import Dispatcher
from aiogram.types import ParseMode
from aiogram.contrib.middlewares.logging import LoggingMiddleware
import asyncio
from aiogram.types import Chat
from config import *
import yandex.cloud.ai.tts.v3.tts_pb2 as tts_pb2
import yandex.cloud.ai.tts.v3.tts_service_pb2_grpc as tts_service_pb2_grpc
from aiogram.dispatcher.filters.state import State, StatesGroup
from aiogram.dispatcher import FSMContext
from aiogram.contrib.fsm_storage.memory import MemoryStorage




class VoiceSelection(StatesGroup):
    Choosing = State()


API_TOKEN = TOKEN

bot = Bot(token=API_TOKEN)
dp = Dispatcher(bot, storage=MemoryStorage())

dp.middleware.setup(LoggingMiddleware())


voice_descriptions = {
    'alena': '–ê–ª—ë–Ω–∞ üíÖ',
    'filipp': '–§–∏–ª–∏–ø–ø üë§',
    'ermil': '–ï—Ä–º–∏–ª üë§',
    'jane': '–î–∂–µ–π–Ω üíÖ',
    'madirus': '–ú–∞–¥–∏—Ä–∞—Å üë§',
    'omazh': '–û–º–∞–∂ üë§',
    'zahar': '–ó–∞—Ö–∞—Ä üë§',
    'dasha': '–î–∞—à–∞ üíÖ',
    'julia': '–Æ–ª–∏—è üíÖ',
    'lera': '–õ–µ—Ä–∞ üíÖ',
    'masha': '–ú–∞—à–∞ üíÖ',
    'marina': '–ú–∞—Ä–∏–Ω–∞ üíÖ',
    'alexander': '–ê–ª–µ–∫—Å–∞–Ω–¥—Ä üë§',
    'kirill': '–ö–∏—Ä–∏–ª–ª üë§',
    'anton': '–ê–Ω—Ç–æ–Ω üë§'
}

def generate_voice_keyboard():
    keyboard = types.InlineKeyboardMarkup()
    voices = list(voice_descriptions.keys())  # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–π —Å–ª–æ–≤–∞—Ä—è
    for i in range(0, len(voices), 3):
        row = []
        for voice in voices[i:i+3]:
            description = voice_descriptions.get(voice, voice)  # –ï—Å–ª–∏ –æ–ø–∏—Å–∞–Ω–∏—è –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–∞–º –≥–æ–ª–æ—Å
            row.append(types.InlineKeyboardButton(text=description, callback_data=f"voice_{voice}"))
        keyboard.row(*row)
    return keyboard

@dp.message_handler(commands=['start'], state="*")
async def handle_start(message: types.Message):
    # –¢–µ–∫—Å—Ç –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —Å —ç–º–æ–¥–∑–∏
    welcome_text = "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –≤ —Ä–µ—á—å. " \
                   "–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Ç–µ–∫—Å—Ç, –∏ —è —Å–æ–∑–¥–∞–º –¥–ª—è —Ç–µ–±—è –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ! üé§"
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –µ–≥–æ –≤ —Ä–µ—á—å
    await bot.send_message(message.chat.id, welcome_text)

@dp.message_handler(commands=['developer'], state="*")
async def handle_developer(message: types.Message):
    # –¢–µ–∫—Å—Ç —Å —Å—Å—ã–ª–∫–æ–π –Ω–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
    developer_text = "–ü—Ä–∏–≤–µ—Ç! –Ø —Å–æ–∑–¥–∞–Ω –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Å—å –¢–∏–º–µ—Ä–ª–∞–Ω–æ–º. –ï—Å–ª–∏ —É —Ç–µ–±—è –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, " \
                     "—Ç—ã –º–æ–∂–µ—à—å –Ω–∞–ø–∏—Å–∞—Ç—å –µ–º—É –≤ —Ç–µ–ª–µ–≥—Ä–∞–º: [–¢–∏–º–µ—Ä–ª–∞–Ω](https://t.me/timaadev) ü§ñ"
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –µ–≥–æ –≤ —Ä–µ—á—å
    await bot.send_message(message.chat.id, developer_text, parse_mode=ParseMode.MARKDOWN)

def synthesize(api_key, text,voice) -> pydub.AudioSegment: 
    request = tts_pb2.UtteranceSynthesisRequest(
        text=text,
        output_audio_spec=tts_pb2.AudioFormatOptions(
            container_audio=tts_pb2.ContainerAudio(
                container_audio_type=tts_pb2.ContainerAudio.WAV
            )
        ),
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–Ω—Ç–µ–∑–∞
       hints=[
    tts_pb2.Hints(voice=voice),  # (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ó–∞–¥–∞–π—Ç–µ –≥–æ–ª–æ—Å. –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é marina
          # (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –£–∫–∞–∂–∏—Ç–µ –∞–º–ø–ª—É–∞, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≥–æ–ª–æ—Å –∏—Ö –∏–º–µ–µ—Ç
    tts_pb2.Hints(speed=1.1)           # (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ó–∞–¥–∞–π—Ç–µ —Å–∫–æ—Ä–æ—Å—Ç—å —Å–∏–Ω—Ç–µ–∑–∞
],

        loudness_normalization_type=tts_pb2.UtteranceSynthesisRequest.LUFS
    )

    # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å —Å–µ—Ä–≤–µ—Ä–æ–º.
    cred = grpc.ssl_channel_credentials()
    channel = grpc.secure_channel('tts.api.cloud.yandex.net:443', cred)
    stub = tts_service_pb2_grpc.SynthesizerStub(channel)

    # –û—Ç–ø—Ä–∞–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞.
    it = stub.UtteranceSynthesis(request, metadata=(

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å IAM-—Ç–æ–∫–µ–Ω–æ–º
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å API-–∫–ª—é—á–æ–º –æ—Ç –∏–º–µ–Ω–∏ —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞
      ('authorization', f'Api-Key {api_key}'),
    ))

    # –°–æ–±–µ—Ä–∏—Ç–µ –∞—É–¥–∏–æ–∑–∞–ø–∏—Å—å –ø–æ –ø–æ—Ä—Ü–∏—è–º.
    try:
        audio = io.BytesIO()
        for response in it:
            audio.write(response.audio_chunk.data)
        audio.seek(0)
        return pydub.AudioSegment.from_wav(audio)
    except grpc._channel._Rendezvous as err:
        print(f'Error code {err._state.code}, message: {err._state.details}')
        raise err


async def check_sub_channels(channels,user_id):
    for channels in channels:
        chat_member = await bot.get_chat_member(chat_id= channels[1],user_id=user_id)
        if chat_member['status'] == 'left':
            return False
        return True
    


@dp.message_handler(content_types=types.ContentTypes.TEXT, state="*")
async def handle_text_message(message: types.Message, state: FSMContext):
    api_key = 'AQVN0fiGepILDWchpaGpBf81jITFo_SQY6AruXBb'  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Å–≤–æ–π API-–∫–ª—é—á
    text = message.text
    keyboard = types.InlineKeyboardMarkup()
    keyboard.add(types.InlineKeyboardButton(text='–ù–µ–º–æ–Ω—Ç–∞–∂ üé®',url='https://t.me/dfdfdfrrr'))
    if await check_sub_channels(channels=CNANNELS, user_id=message.from_user.id):

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        await state.update_data(text=text)

        # –í–æ–π—Ç–∏ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤—ã–±–æ—Ä–∞ –≥–æ–ª–æ—Å–∞
        await VoiceSelection.Choosing.set()

        # –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –≤—ã–±–æ—Ä–æ–º –≥–æ–ª–æ—Å–∞
        await bot.send_message(message.chat.id, "–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å:", reply_markup=generate_voice_keyboard())
    else:
        await bot.send_message(message.chat.id, text=NOT_SUB_MESSAGE,reply_markup=keyboard,parse_mode='HTML')


@dp.callback_query_handler(lambda c: c.data.startswith('voice_'), state=VoiceSelection.Choosing)
async def process_voice_choice(callback_query: types.CallbackQuery, state: FSMContext):
    # –ò–∑–≤–ª–µ—á—å –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å –∏–∑ –¥–∞–Ω–Ω—ã—Ö –∫–æ–ª–±—ç–∫–∞
    selected_voice = callback_query.data.split('_')[1]

    # –ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    data = await state.get_data()
    text = data['text']

    # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏
    api_key = 'AQVN0fiGepILDWchpaGpBf81jITFo_SQY6AruXBb'  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Å–≤–æ–π API-–∫–ª—é—á

    audio = synthesize(api_key, text[0:249], voice=selected_voice)

    # –û—Ç–ø—Ä–∞–≤–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    with io.BytesIO() as audio_buffer:
        audio.export(audio_buffer, format='wav')
        audio_buffer.seek(0)
        await bot.send_voice(callback_query.from_user.id, audio_buffer, caption=text[0:259] + '....',
                             parse_mode=ParseMode.MARKDOWN)

    # –í—ã–π—Ç–∏ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤—ã–±–æ—Ä–∞ –≥–æ–ª–æ—Å–∞
    await state.finish()

    # –û—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –∫–æ–ª–±—ç–∫, —á—Ç–æ–±—ã –∑–∞–∫—Ä—ã—Ç—å –≤—Å–ø–ª—ã–≤–∞—é—â–µ–µ –æ–∫–Ω–æ —Å –≤—ã–±–æ—Ä–æ–º –≥–æ–ª–æ—Å–∞
    await bot.answer_callback_query(callback_query.id, text=f"–í—ã–±—Ä–∞–Ω –≥–æ–ª–æ—Å: {selected_voice}")
if __name__ == '__main__':
    from aiogram import executor

    loop = asyncio.get_event_loop()
    loop.create_task(bot.send_message(5455171373, '–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω'))  # –ó–∞–º–µ–Ω–∏—Ç–µ 123456789 –Ω–∞ –≤–∞—à ID —á–∞—Ç–∞
    executor.start_polling(dp, skip_updates=True)
